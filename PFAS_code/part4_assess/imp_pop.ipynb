{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the population impacted by Pfas\n",
    "\n",
    "计算被PFAS影响的人口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import myfunction as mf\n",
    "path_data_raw = \"C:/Users/dell/OneDrive/file/\"\n",
    "path_country_nc = \"C:/Users/dell/OneDrive/file/nc\"\n",
    "path_country_csv = \"C:/Users/dell/OneDrive/file/csv/\"\n",
    "path_one_spdb = 'C:/Users/dell/OneDrive/file/SPDB/'\n",
    "drive_letter = 'E:'\n",
    "\n",
    "path_pre = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part0_treat/pretreatment/\"\n",
    "path_match = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part0_treat/match/\"\n",
    "path_semdata = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part0_treat/semdata/\"\n",
    "\n",
    "\n",
    "path_2_preanalysis_data = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part2_sem/preanalysis/\"\n",
    "path_2_preanalysis_fig = drive_letter + \"/wyy/code_project/running_outcome/final_fig/SPDB/part2_sem/preanalysis/\"\n",
    "\n",
    "\n",
    "path_3_sw_forecast = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part3_forecast/sw_forecast/\"\n",
    "path_temp = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/temp/\"\n",
    "\n",
    "path_4_risk_assess = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part4_assess/\"\n",
    "path_4_risk_assess_grid = drive_letter + \"/wyy/code_project/running_outcome/final_data/SPDB/part4_assess/grid/\"\n",
    "\n",
    "path_1_describe_fig_fish = drive_letter + \"/wyy/code_project/running_outcome/final_fig/SPDB/part1_describe/fish_diff/\"\n",
    "path_1_describe_global_map = drive_letter + \"/wyy/code_project/running_outcome/final_fig/SPDB/part1_describe/global_map/\"\n",
    "\n",
    "mark_num = \"25\"\n",
    "meta_name = \"meta_data.csv\"\n",
    "list_pfas =['PFOA', 'PFNA', 'PFDA', 'PFUnDA','PFDoDA','PFTrDA', 'PFTeDA', 'PFHxS', 'PFOS', 'FOSA', 'PFBA', 'PFPeA', 'PFHxA', 'PFHpA','PFBS']\n",
    "list_pfas_lc = ['PFOA', 'PFNA', 'PFDA', 'PFUnDA','PFDoDA','PFTrDA', 'PFTeDA', 'PFHxS', 'PFOS', 'FOSA']\n",
    "list_pfas_sc = ['PFBA', 'PFPeA', 'PFHxA', 'PFHpA','PFBS']\n",
    "list_color = [\"#4d8cbf\", \"#4f9c8b\", \"#555c6c\", \"#d77563\", \"#7d84a8\", \"#84aeb8\", \"#c3473b\", \"#89756d\",\"#ffb3cc\",\"#9a7ebf\",\"#ffddb8\", \"#c4eaff\", \"#d1c6ff\", \"#c2ffbf\", \"#f5f5b0\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，结果已保存到per_wiw.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "os.chdir(r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\hi')\n",
    "output_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\hi'\n",
    "\n",
    "\n",
    "country_df = pd.read_csv('country.csv')\n",
    "wiw_df = pd.read_csv('without_improved_water.csv')\n",
    "pop_df = pd.read_csv('country_pop.csv')\n",
    "\n",
    "country_map = country_df[['country_id', 'country_code', 'region']].set_index('country_code')\n",
    "wiw_df = wiw_df.merge(country_map, left_on='country_code', right_index=True)\n",
    "wiw_df = wiw_df[['country_id', 'year', 'wiw', 'region']]\n",
    "wiw_df['wiw'] = wiw_df.groupby('country_id')['wiw'].transform(lambda x: x.fillna(x.median()))\n",
    "wiw_df['wiw'] = wiw_df['wiw'].fillna(wiw_df.groupby('year')['wiw'].transform('median'))\n",
    "wiw_df['wiw'] = wiw_df['wiw'].round().astype(int)\n",
    "result_df = wiw_df.merge(pop_df, on=['country_id', 'year'])\n",
    "result_df['per_wiw'] = (result_df['wiw'] / result_df['pop']).round(8)\n",
    "\n",
    "def adjust_per_wiw(row, median_per_wiw):\n",
    "    if row['pop'] == 0 or row['wiw'] == 0:\n",
    "        return median_per_wiw\n",
    "    return row['per_wiw']\n",
    "\n",
    "# group by region and year to get the median per_wiw\n",
    "for (region, year), group in result_df.groupby(['region', 'year']):\n",
    "    median_per_wiw = group['per_wiw'].median()\n",
    "    result_df.loc[(result_df['region'] == region) & (result_df['year'] == year), 'per_wiw'] = \\\n",
    "        result_df.loc[(result_df['region'] == region) & (result_df['year'] == year)].apply(\n",
    "            adjust_per_wiw, axis=1, median_per_wiw=median_per_wiw)\n",
    "\n",
    "output_file = os.path.join(output_path, \"per_wiw.csv\")\n",
    "result_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"处理完成，结果已保存到per_wiw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\progress\\anaconda2\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1204: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    }
   ],
   "source": [
    "df_per_wiw = pd.read_csv(output_file)\n",
    "df_per_wiw = df_per_wiw[['year','country_id','per_wiw']]\n",
    "df_grid = pd.read_csv(path_4_risk_assess_grid + 'new_grid_year.csv')\n",
    "df_grid = df_grid[['lon', 'lat', 'year','country_id']]\n",
    "\n",
    "df_grid_per_wiw = df_grid.merge(df_per_wiw, on=['country_id', 'year'])\n",
    "df_grid_per_wiw = df_grid_per_wiw[['lon', 'lat', 'year','per_wiw']]\n",
    "df_grid_per_wiw.to_csv(path_4_risk_assess_grid + 'per_wiw_grid_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "input_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\thq'\n",
    "output_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\thq'\n",
    "grid_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\grid'\n",
    "\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "def calculate_statistics(df, prefix):\n",
    "    stats_df = df[['lon', 'lat', 'year']].copy()\n",
    "    thq_columns = df.columns[3:]\n",
    "    \n",
    "    stats_df[f'{prefix}_min'] = df[thq_columns].min(axis=1)\n",
    "    stats_df[f'{prefix}_max'] = df[thq_columns].max(axis=1)\n",
    "    stats_df[f'{prefix}_2.5%'] = df[thq_columns].quantile(0.025, axis=1)\n",
    "    stats_df[f'{prefix}_50%'] = df[thq_columns].median(axis=1)\n",
    "    stats_df[f'{prefix}_97.5%'] = df[thq_columns].quantile(0.975, axis=1)\n",
    "    stats_df[f'{prefix}_mean'] = df[thq_columns].mean(axis=1)\n",
    "    stats_df[f'{prefix}_SD'] = df[thq_columns].std(axis=1)\n",
    "    \n",
    "    return stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "input_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\thq'\n",
    "output_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\thq'\n",
    "grid_path = r'E:\\wyy\\code_project\\running_outcome\\final_data\\SPDB\\part4_assess\\grid'\n",
    "per_wiw_df = pd.read_csv(os.path.join(grid_path, 'per_wiw_grid_year.csv'))\n",
    "pop_df = pd.read_csv(os.path.join(grid_path, 'population_year.csv'))\n",
    "\n",
    "pop_data = pop_df.merge(per_wiw_df, on=['lon', 'lat', 'year'], how='left')\n",
    "pop_data['per_wiw'] = pop_data['per_wiw'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "per_wiw_df = pd.read_csv(os.path.join(grid_path, 'per_wiw_grid_year.csv'))\n",
    "pop_df = pd.read_csv(os.path.join(grid_path, 'population_year.csv'))\n",
    "\n",
    "pop_data = pop_df.merge(per_wiw_df, on=['lon', 'lat', 'year'], how='left')\n",
    "pop_data['per_wiw'] = pop_data['per_wiw'].fillna(0)\n",
    "\n",
    "pop_dict = pop_data.set_index(['lon', 'lat', 'year']).to_dict()\n",
    "\n",
    "lr_df = pd.read_csv(os.path.join(input_path, 'lr_merged_thq.csv'))\n",
    "lr_imp_pop = lr_df.copy()\n",
    "thq_columns = lr_df.columns[3:]\n",
    "\n",
    "for col in tqdm(thq_columns, desc=\"Processing lr columns\"):\n",
    "    new_col_name = f'imp_pop_{col[9:]}' \n",
    "\n",
    "    mask = (lr_df[col]) >= 1\n",
    "    lr_imp_pop[new_col_name] = np.where(mask, \n",
    "                                        [pop_dict['pop'].get((lon, lat, year), 0) \n",
    "                                         for lon, lat, year in zip(lr_df['lon'], lr_df['lat'], lr_df['year'])],\n",
    "                                        0)\n",
    "lr_imp_pop = lr_imp_pop.drop(columns=thq_columns)\n",
    "lr_imp_pop.to_csv(os.path.join(output_path, 'lr_imp_pop_d.csv'), index=False)\n",
    "\n",
    "lr_stats_pop = calculate_statistics(lr_imp_pop, 'imp_pop')\n",
    "lr_stats_pop.to_csv(os.path.join(output_path, 'lr_pop_statistics_d.csv'), index=False)\n",
    "\n",
    "\n",
    "\n",
    "sw_df = pd.read_csv(os.path.join(input_path, 'sw_merged_thq.csv'))\n",
    "sw_imp_pop = sw_df.copy()\n",
    "thq_columns = sw_df.columns[3:]\n",
    "\n",
    "for col in tqdm(thq_columns, desc=\"Processing sw columns\"):\n",
    "    new_col_name = f'imp_pop_{col[10:]}'\n",
    "\n",
    "    mask = sw_df[col] >= 1\n",
    "    sw_imp_pop[new_col_name] = np.where(mask, \n",
    "                                        [pop_dict['pop'].get((lon, lat, year), 0) * pop_dict['per_wiw'].get((lon, lat, year), 0)\n",
    "                                         for lon, lat, year in zip(sw_df['lon'], sw_df['lat'], sw_df['year'])],\n",
    "                                        0)\n",
    "\n",
    "sw_imp_pop = sw_imp_pop.drop(columns=thq_columns)\n",
    "sw_imp_pop.to_csv(os.path.join(output_path, 'sw_imp_pop.csv'), index=False)\n",
    "\n",
    "sw_stats_pop = calculate_statistics(sw_imp_pop, 'imp_pop')\n",
    "sw_stats_pop.to_csv(os.path.join(output_path, 'sw_pop_statistics.csv'), index=False)\n",
    "\n",
    "merge_df = pd.read_csv(os.path.join(input_path, 'merged_thq.csv'))\n",
    "merge_imp_pop = merge_df.copy()\n",
    "thq_columns = merge_df.columns[3:]\n",
    "\n",
    "for col in tqdm(thq_columns, desc=\"Processing merge columns\"):\n",
    "    new_col_name = f'imp_pop_{col[10:]}'\n",
    "\n",
    "    mask = merge_df[col] >= 1\n",
    "\n",
    "    merge_imp_pop[new_col_name] = np.where(mask, \n",
    "                                        [pop_dict['pop'].get((lon, lat, year), 0) * pop_dict['per_wiw'].get((lon, lat, year), 0)\n",
    "                                         for lon, lat, year in zip(merge_df['lon'], merge_df['lat'], merge_df['year'])],\n",
    "                                        0)\n",
    "\n",
    "merge_imp_pop = merge_imp_pop.drop(columns=thq_columns)\n",
    "merge_imp_pop.to_csv(os.path.join(output_path, 'merge_imp_pop.csv'), index=False)\n",
    "\n",
    "merge_stats_pop = calculate_statistics(merge_imp_pop, 'imp_pop')\n",
    "merge_stats_pop.to_csv(os.path.join(output_path, 'merge_pop_statistics.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_imp_pop = pd.read_csv(os.path.join(output_path, 'lr_imp_pop_d.csv'))\n",
    "lr_stats_pop = calculate_statistics(lr_imp_pop, 'imp_pop')\n",
    "lr_stats_pop.to_csv(os.path.join(output_path, 'lr_pop_statistics_d.csv'), index=False)\n",
    "\n",
    "combined_imp_pop = lr_imp_pop.copy()\n",
    "sw_imp_pop_cols = sw_imp_pop.columns[3:]\n",
    "other_imp_pop_cols = merge_imp_pop.columns[3:]\n",
    "\n",
    "\n",
    "combined_imp_pop.to_csv(os.path.join(output_path, 'combined_imp_pop.csv'), index=False)\n",
    "\n",
    "combined_stats_pop = calculate_statistics(combined_imp_pop, 'imp_pop')\n",
    "combined_stats_pop.to_csv(os.path.join(output_path, 'combined_pop_statistics.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(df, prefix):\n",
    "    stats_df = df[['lon', 'lat', 'year']].copy()\n",
    "    thq_columns = df.columns[3:]\n",
    "    \n",
    "    stats_df[f'{prefix}_min'] = df[thq_columns].min(axis=1)\n",
    "    stats_df[f'{prefix}_max'] = df[thq_columns].max(axis=1)\n",
    "    stats_df[f'{prefix}_2.5%'] = df[thq_columns].quantile(0.025, axis=1)\n",
    "    stats_df[f'{prefix}_5%'] = df[thq_columns].quantile(0.05, axis=1)\n",
    "    stats_df[f'{prefix}_10%'] = df[thq_columns].quantile(0.1, axis=1)\n",
    "    stats_df[f'{prefix}_20%'] = df[thq_columns].quantile(0.2, axis=1)\n",
    "    stats_df[f'{prefix}_50%'] = df[thq_columns].median(axis=1)\n",
    "    stats_df[f'{prefix}_80%'] = df[thq_columns].quantile(0.8, axis=1)\n",
    "    stats_df[f'{prefix}_90%'] = df[thq_columns].quantile(0.9, axis=1)\n",
    "    stats_df[f'{prefix}_95%'] = df[thq_columns].quantile(0.95, axis=1)\n",
    "    stats_df[f'{prefix}_97.5%'] = df[thq_columns].quantile(0.975, axis=1)\n",
    "    stats_df[f'{prefix}_mean'] = df[thq_columns].mean(axis=1)\n",
    "    stats_df[f'{prefix}_SD'] = df[thq_columns].std(axis=1)\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats_pop = calculate_statistics(combined_imp_pop, 'imp_pop')\n",
    "combined_stats_pop.to_csv(os.path.join(output_path, 'combined_pop_statistics2.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
